import os
from tqdm import tqdm
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import torch
from torchvision import transforms
from torchvision.utils import save_image
from torchvision.datasets import MNIST
from CVAE_1 import VAE, CVAE

def train(model, optimizer, data_loader, device, name='VAE'):
    model.train()
    total_loss = 0
    pbar = tqdm(data_loader)
    for X, y in pbar:
        batch_size = X.shape[0]
        X = X.view(batch_size, -1).to(device)
        model.zero_grad()
        if name == 'VAE':
            mu_prime, mu, log_var = model(X)
        else:
            mu_prime, mu, log_var = model(X, y)
        loss = model.loss(X.view(batch_size, -1), mu_prime, mu, log_var)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        pbar.set_description('Loss: {loss:.4f}'.format(loss=loss.item()))

    return total_loss / len(data_loader)

@torch.no_grad()
def save_res(vae, cvae, data, latent_size, device):
    save_dir = './save_img/'
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    num_classes = len(data.classes)
    # raw samples from dataset
    out = []
    for i in range(num_classes):
        img = data.data[torch.where(data.targets == i)[0][:num_classes]]
        out.append(img)
    out = torch.stack(out).transpose(0, 1).reshape(-1, 1, 28, 28)
    save_image(out.float(), save_dir + 'raw_samples.png', nrow=num_classes, normalize=True)

    # samples generated by vanilla VAE
    z = torch.randn(num_classes ** 2, latent_size).to(device)
    out = vae.decoder(z)
    save_image(out.view(-1, 1, 28, 28), save_dir + 'vae_samples.png', nrow=num_classes)

    # sample generated by CVAE
    z = torch.randn(num_classes ** 2, latent_size).to(device)
    y = torch.arange(num_classes).repeat(num_classes).to(device)
    z_given_Y = torch.cat((z, y.unsqueeze(1)), dim=1)
    out = cvae.decoder(z_given_Y)
    save_image(out.view(-1, 1, 28, 28), save_dir + 'cvae_samples.png', nrow=num_classes)

def main():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    device = torch.device(device)

    batch_size = 256 * 64
    epochs = 50
    latent_size = 64
    in_features = 28 * 28
    lr = 0.001
    data = MNIST('./data', download=True, transform=transforms.ToTensor())
    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)

    # train VAE
    vae = VAE(in_features, latent_size).to(device)
    optimizer = torch.optim.AdamW(vae.parameters(), lr=lr)

    print('Start Training VAE...')
    for epoch in range(1, 1 + epochs):
        loss = train(vae, optimizer, data_loader, device, name='VAE')
        print("Epochs: {epoch}, AvgLoss: {loss:.4f}".format(epoch=epoch, loss=loss))
    print('Training for VAE has been done.')

    # train VCAE
    cvae = CVAE(in_features, latent_size, y_size=1).to(device)
    optimizer = torch.optim.AdamW(cvae.parameters(), lr=lr)

    print('Start Training CVAE...')
    for epoch in range(1, 1 + epochs):
        loss = train(cvae, optimizer, data_loader, device, name='CVAE')
        print("Epochs: {epoch}, AvgLoss: {loss:.4f}".format(epoch=epoch, loss=loss))
    print('Training for CVAE has been done.')

    save_res(vae, cvae, data, latent_size, device)

if __name__ == '__main__':
    main()
    print("All done!")